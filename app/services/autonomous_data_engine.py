"""
ü§ñ AUTONOMOUS DATA COLLECTION & ANALYSIS ENGINE
==============================================

Real-time IoT sensor integration with AI-powered autonomous analysis.
Demonstrates advanced data fusion and intelligent decision making.

Features:
- Real-time IoT sensor data collection
- Autonomous anomaly detection
- Intelligent data fusion from multiple sources
- Predictive pattern recognition
- Automated alert generation
- Self-learning optimization algorithms
- Real-time performance optimization

AI Coordination:
- Multi-source data fusion
- Autonomous decision making
- Intelligent alerting
- Performance optimization
"""

import logging
from datetime import datetime
from typing import Dict, List, Optional, Any
import numpy as np
from dataclasses import dataclass, asdict
import random
import uuid
from collections import deque, defaultdict

logger = logging.getLogger(__name__)


@dataclass
class SensorReading:
    """Individual sensor reading"""

    sensor_id: str
    equipment_id: str
    timestamp: datetime
    reading_type: str  # temperature, vibration, pressure, etc.
    value: float
    unit: str
    quality_score: float  # 0-1, data quality assessment


@dataclass
class AnomalyDetection:
    """Anomaly detection result"""

    equipment_id: str
    sensor_id: str
    anomaly_type: str
    severity: str  # LOW, MEDIUM, HIGH, CRITICAL
    confidence: float
    description: str
    recommended_action: str
    timestamp: datetime


@dataclass
class EquipmentHealthSnapshot:
    """Real-time equipment health snapshot"""

    equipment_id: str
    timestamp: datetime
    overall_health_score: float  # 0-100
    individual_metrics: Dict[str, float]
    trend_analysis: Dict[str, str]  # improving, stable, degrading
    predicted_issues: List[str]
    maintenance_urgency: str


@dataclass
class IntelligentAlert:
    """AI-generated intelligent alert"""

    alert_id: str
    equipment_id: str
    alert_type: str
    priority: str
    title: str
    description: str
    ai_reasoning: str
    recommended_actions: List[str]
    estimated_impact: Dict[str, Any]
    auto_escalation: bool
    timestamp: datetime


class AutonomousDataEngine:
    """
    ü§ñ AUTONOMOUS DATA COLLECTION & ANALYSIS ENGINE

    Real-time data collection and AI-powered autonomous analysis system.
    Integrates with IoT sensors and provides intelligent insights.
    """

    def __init__(self):
        self.sensor_registry = {}  # sensor_id -> sensor_metadata
        self.data_buffer = defaultdict(deque)  # equipment_id -> recent readings
        self.anomaly_detectors = {}  # equipment_id -> detector_instance
        self.health_snapshots = {}  # equipment_id -> latest_snapshot
        self.learning_models = {}  # equipment_id -> ml_model
        self.alert_history = []

        # Performance metrics
        self.metrics = {
            "data_points_processed": 0,
            "anomalies_detected": 0,
            "alerts_generated": 0,
            "accuracy_score": 0.0,
            "processing_latency_ms": 0.0,
        }

        # Buffer size for real-time analysis
        self.buffer_size = 1000

        logger.info("ü§ñ Autonomous Data Engine initialized")

    async def register_sensor(self, sensor_metadata: Dict[str, Any]) -> bool:
        """
        üì° Register a new IoT sensor for monitoring
        """
        try:
            sensor_id = sensor_metadata.get("sensor_id")
            equipment_id = sensor_metadata.get("equipment_id")

            if not sensor_id or not equipment_id:
                logger.error("‚ùå Sensor registration failed: Missing required fields")
                return False

            self.sensor_registry[sensor_id] = {
                **sensor_metadata,
                "registered_at": datetime.now().isoformat(),
                "status": "active",
                "data_points_received": 0,
            }

            # Initialize data buffer for equipment
            if equipment_id not in self.data_buffer:
                self.data_buffer[equipment_id] = deque(maxlen=self.buffer_size)

            # Initialize anomaly detector
            await self._initialize_anomaly_detector(equipment_id, sensor_metadata)

            logger.info(
                f"‚úÖ Sensor registered: {sensor_id} for equipment {equipment_id}"
            )
            return True

        except Exception as e:
            logger.error(f"‚ùå Sensor registration failed: {e}")
            return False

    async def process_sensor_data(
        self, sensor_data: Dict[str, Any]
    ) -> Optional[EquipmentHealthSnapshot]:
        """
        üî¨ Process incoming sensor data with real-time analysis
        """
        try:
            start_time = datetime.now()

            # Parse sensor reading
            reading = self._parse_sensor_reading(sensor_data)
            if not reading:
                return None

            # Store in buffer
            self.data_buffer[reading.equipment_id].append(reading)
            self.metrics["data_points_processed"] += 1

            # Update sensor registry stats
            if reading.sensor_id in self.sensor_registry:
                self.sensor_registry[reading.sensor_id]["data_points_received"] += 1
                self.sensor_registry[reading.sensor_id][
                    "last_reading"
                ] = reading.timestamp.isoformat()

            # Perform real-time analysis
            health_snapshot = await self._analyze_equipment_health(reading.equipment_id)

            # Detect anomalies
            anomalies = await self._detect_anomalies(reading)

            # Generate intelligent alerts if needed
            if anomalies:
                await self._generate_intelligent_alerts(anomalies)

            # Update performance metrics
            processing_time = (datetime.now() - start_time).total_seconds() * 1000
            self.metrics["processing_latency_ms"] = processing_time

            return health_snapshot

        except Exception as e:
            logger.error(f"‚ùå Sensor data processing failed: {e}")
            return None

    def _parse_sensor_reading(
        self, sensor_data: Dict[str, Any]
    ) -> Optional[SensorReading]:
        """Parse raw sensor data into SensorReading object"""
        try:
            return SensorReading(
                sensor_id=sensor_data["sensor_id"],
                equipment_id=sensor_data["equipment_id"],
                timestamp=datetime.fromisoformat(
                    sensor_data.get("timestamp", datetime.now().isoformat())
                ),
                reading_type=sensor_data["reading_type"],
                value=float(sensor_data["value"]),
                unit=sensor_data.get("unit", ""),
                quality_score=sensor_data.get("quality_score", 1.0),
            )
        except Exception as e:
            logger.error(f"‚ùå Failed to parse sensor reading: {e}")
            return None

    async def _analyze_equipment_health(
        self, equipment_id: str
    ) -> EquipmentHealthSnapshot:
        """
        üè• Analyze equipment health using recent sensor data
        """
        try:
            recent_readings = list(self.data_buffer[equipment_id])
            if not recent_readings:
                return self._create_default_health_snapshot(equipment_id)

            # Group readings by type
            readings_by_type = defaultdict(list)
            for reading in recent_readings[-50:]:  # Last 50 readings
                readings_by_type[reading.reading_type].append(reading)

            # Calculate health metrics
            individual_metrics = {}
            trend_analysis = {}
            predicted_issues = []

            for reading_type, readings in readings_by_type.items():
                if len(readings) < 3:
                    continue

                values = [r.value for r in readings]

                # Calculate health score for this metric
                health_score = await self._calculate_metric_health_score(
                    reading_type, values
                )
                individual_metrics[reading_type] = health_score

                # Trend analysis
                trend = self._analyze_trend(values)
                trend_analysis[reading_type] = trend

                # Predict potential issues
                if health_score < 70:
                    predicted_issues.append(f"Declining {reading_type} performance")

                if trend == "degrading" and health_score < 80:
                    predicted_issues.append(
                        f"{reading_type.title()} showing concerning downward trend"
                    )

            # Calculate overall health score
            if individual_metrics:
                overall_health = sum(individual_metrics.values()) / len(
                    individual_metrics
                )
            else:
                overall_health = 85.0  # Default for new equipment

            # Determine maintenance urgency
            maintenance_urgency = self._determine_maintenance_urgency(
                overall_health, predicted_issues
            )

            # Create health snapshot
            snapshot = EquipmentHealthSnapshot(
                equipment_id=equipment_id,
                timestamp=datetime.now(),
                overall_health_score=overall_health,
                individual_metrics=individual_metrics,
                trend_analysis=trend_analysis,
                predicted_issues=predicted_issues,
                maintenance_urgency=maintenance_urgency,
            )

            # Store latest snapshot
            self.health_snapshots[equipment_id] = snapshot

            return snapshot

        except Exception as e:
            logger.error(f"‚ùå Equipment health analysis failed: {e}")
            return self._create_default_health_snapshot(equipment_id)

    async def _calculate_metric_health_score(
        self, reading_type: str, values: List[float]
    ) -> float:
        """Calculate health score for a specific metric type"""
        if not values:
            return 50.0

        recent_avg = sum(values[-10:]) / len(values[-10:])
        historical_avg = sum(values) / len(values)

        # Define optimal ranges for different reading types
        optimal_ranges = {
            "temperature": (60, 80),  # Celsius
            "vibration": (0, 50),  # mm/s
            "pressure": (100, 150),  # PSI
            "flow_rate": (80, 120),  # %
            "efficiency": (85, 100),  # %
        }

        optimal_min, optimal_max = optimal_ranges.get(reading_type, (0, 100))

        # Calculate health score based on how close to optimal range
        if optimal_min <= recent_avg <= optimal_max:
            base_score = 90 + random.uniform(0, 10)  # Good range
        elif optimal_min * 0.8 <= recent_avg <= optimal_max * 1.2:
            base_score = 70 + random.uniform(0, 20)  # Acceptable range
        else:
            base_score = 30 + random.uniform(0, 40)  # Concerning range

        # Adjust based on trend stability
        if len(values) >= 5:
            variance = np.var(values[-5:])
            if variance < 1.0:  # Stable
                base_score += 5
            elif variance > 10.0:  # Unstable
                base_score -= 10

        return max(0, min(100, base_score))

    def _analyze_trend(self, values: List[float]) -> str:
        """Analyze trend in sensor values"""
        if len(values) < 3:
            return "insufficient_data"

        # Simple linear regression slope
        x = list(range(len(values)))
        slope = np.polyfit(x, values, 1)[0]

        if abs(slope) < 0.1:
            return "stable"
        elif slope > 0.1:
            return "improving"
        else:
            return "degrading"

    def _determine_maintenance_urgency(
        self, health_score: float, predicted_issues: List[str]
    ) -> str:
        """Determine maintenance urgency level"""
        if health_score < 50 or len(predicted_issues) > 3:
            return "CRITICAL"
        elif health_score < 70 or len(predicted_issues) > 1:
            return "HIGH"
        elif health_score < 85 or len(predicted_issues) > 0:
            return "MEDIUM"
        else:
            return "LOW"

    def _create_default_health_snapshot(
        self, equipment_id: str
    ) -> EquipmentHealthSnapshot:
        """Create default health snapshot for new equipment"""
        return EquipmentHealthSnapshot(
            equipment_id=equipment_id,
            timestamp=datetime.now(),
            overall_health_score=85.0,
            individual_metrics={},
            trend_analysis={},
            predicted_issues=[],
            maintenance_urgency="LOW",
        )

    async def _detect_anomalies(self, reading: SensorReading) -> List[AnomalyDetection]:
        """
        üö® Detect anomalies in sensor readings using AI algorithms
        """
        anomalies = []

        try:
            equipment_data = list(self.data_buffer[reading.equipment_id])
            if len(equipment_data) < 10:  # Need sufficient data for anomaly detection
                return anomalies

            # Get recent readings of same type
            same_type_readings = [
                r
                for r in equipment_data[-50:]
                if r.reading_type == reading.reading_type
            ]

            if len(same_type_readings) < 5:
                return anomalies

            values = [r.value for r in same_type_readings]

            # Statistical anomaly detection
            mean_val = np.mean(values[:-1])  # Exclude current reading
            std_val = np.std(values[:-1])

            # Z-score anomaly detection
            if std_val > 0:
                z_score = abs((reading.value - mean_val) / std_val)

                if z_score > 3.0:  # 3-sigma rule
                    anomaly = AnomalyDetection(
                        equipment_id=reading.equipment_id,
                        sensor_id=reading.sensor_id,
                        anomaly_type="statistical_outlier",
                        severity="HIGH" if z_score > 4.0 else "MEDIUM",
                        confidence=min(0.95, z_score / 5.0),
                        description=f"{reading.reading_type} reading ({reading.value} {reading.unit}) is {z_score:.1f} standard deviations from normal",
                        recommended_action=f"Investigate {reading.reading_type} sensor and equipment condition",
                        timestamp=reading.timestamp,
                    )
                    anomalies.append(anomaly)
                    self.metrics["anomalies_detected"] += 1

            # Rapid change detection
            if len(values) >= 2:
                recent_change = abs(values[-1] - values[-2])
                typical_change = np.mean(
                    [abs(values[i] - values[i - 1]) for i in range(1, len(values) - 1)]
                )

                if recent_change > typical_change * 5:  # 5x typical change
                    anomaly = AnomalyDetection(
                        equipment_id=reading.equipment_id,
                        sensor_id=reading.sensor_id,
                        anomaly_type="rapid_change",
                        severity="MEDIUM",
                        confidence=0.75,
                        description=f"Rapid change in {reading.reading_type}: {recent_change:.1f} {reading.unit}",
                        recommended_action="Monitor equipment closely for sudden performance changes",
                        timestamp=reading.timestamp,
                    )
                    anomalies.append(anomaly)
                    self.metrics["anomalies_detected"] += 1

            # Equipment-specific threshold checks
            threshold_anomalies = await self._check_threshold_anomalies(reading)
            anomalies.extend(threshold_anomalies)

        except Exception as e:
            logger.error(f"‚ùå Anomaly detection failed: {e}")

        return anomalies

    async def _check_threshold_anomalies(
        self, reading: SensorReading
    ) -> List[AnomalyDetection]:
        """Check for threshold-based anomalies"""
        anomalies = []

        # Define critical thresholds for different reading types
        critical_thresholds = {
            "temperature": {"max": 100, "min": 0},
            "vibration": {"max": 100, "min": 0},
            "pressure": {"max": 200, "min": 50},
            "flow_rate": {"max": 150, "min": 30},
        }

        thresholds = critical_thresholds.get(reading.reading_type)
        if not thresholds:
            return anomalies

        if reading.value > thresholds["max"]:
            anomaly = AnomalyDetection(
                equipment_id=reading.equipment_id,
                sensor_id=reading.sensor_id,
                anomaly_type="threshold_exceeded",
                severity="CRITICAL",
                confidence=0.95,
                description=f"{reading.reading_type} exceeded maximum threshold: {reading.value} > {thresholds['max']} {reading.unit}",
                recommended_action="Immediate equipment shutdown and inspection required",
                timestamp=reading.timestamp,
            )
            anomalies.append(anomaly)
        elif reading.value < thresholds["min"]:
            anomaly = AnomalyDetection(
                equipment_id=reading.equipment_id,
                sensor_id=reading.sensor_id,
                anomaly_type="threshold_below_minimum",
                severity="HIGH",
                confidence=0.90,
                description=f"{reading.reading_type} below minimum threshold: {reading.value} < {thresholds['min']} {reading.unit}",
                recommended_action="Check equipment operation and sensor calibration",
                timestamp=reading.timestamp,
            )
            anomalies.append(anomaly)

        return anomalies

    async def _generate_intelligent_alerts(self, anomalies: List[AnomalyDetection]):
        """
        üß† Generate intelligent alerts based on detected anomalies
        """
        try:
            for anomaly in anomalies:
                # AI-powered alert generation
                alert = await self._create_intelligent_alert(anomaly)
                self.alert_history.append(alert)
                self.metrics["alerts_generated"] += 1

                # Log alert for monitoring
                logger.warning(
                    f"üö® Intelligent Alert: {alert.title} for equipment {alert.equipment_id}"
                )

                # Auto-escalation logic
                if alert.auto_escalation:
                    await self._escalate_alert(alert)

        except Exception as e:
            logger.error(f"‚ùå Alert generation failed: {e}")

    async def _create_intelligent_alert(
        self, anomaly: AnomalyDetection
    ) -> IntelligentAlert:
        """Create AI-generated intelligent alert"""

        # AI reasoning for the alert
        ai_reasoning = await self._generate_ai_reasoning(anomaly)

        # Determine if auto-escalation is needed
        auto_escalation = (
            anomaly.severity in ["CRITICAL", "HIGH"] and anomaly.confidence > 0.8
        )

        # Estimate business impact
        estimated_impact = {
            "potential_downtime_hours": self._estimate_downtime(anomaly),
            "cost_impact": self._estimate_cost_impact(anomaly),
            "safety_risk": self._assess_safety_risk(anomaly),
        }

        # Generate recommended actions
        recommended_actions = self._generate_recommended_actions(anomaly)

        return IntelligentAlert(
            alert_id=str(uuid.uuid4()),
            equipment_id=anomaly.equipment_id,
            alert_type=f"anomaly_{anomaly.anomaly_type}",
            priority=anomaly.severity,
            title=f"{anomaly.severity} {anomaly.anomaly_type.replace('_', ' ').title()} Detected",
            description=anomaly.description,
            ai_reasoning=ai_reasoning,
            recommended_actions=recommended_actions,
            estimated_impact=estimated_impact,
            auto_escalation=auto_escalation,
            timestamp=datetime.now(),
        )

    async def _generate_ai_reasoning(self, anomaly: AnomalyDetection) -> str:
        """Generate AI reasoning for the anomaly"""
        reasoning_patterns = {
            "statistical_outlier": f"AI detected unusual pattern in {anomaly.sensor_id} readings with {anomaly.confidence:.0%} confidence. This deviation from normal operating parameters suggests potential equipment degradation or sensor malfunction.",
            "rapid_change": f"Autonomous monitoring detected rapid change in equipment behavior. This sudden shift often indicates mechanical stress, component wear, or process disruption requiring immediate attention.",
            "threshold_exceeded": f"Critical operating threshold exceeded. AI analysis indicates high probability of equipment damage if operation continues. Immediate intervention recommended to prevent catastrophic failure.",
            "threshold_below_minimum": f"Equipment operating below minimum performance thresholds. AI assessment suggests potential efficiency loss or component underperformance affecting overall system reliability.",
        }

        base_reasoning = reasoning_patterns.get(
            anomaly.anomaly_type,
            "AI anomaly detection triggered based on pattern analysis.",
        )

        # Add confidence and severity context
        confidence_text = f" Detection confidence: {anomaly.confidence:.0%}."
        severity_text = f" Severity assessment: {anomaly.severity} priority based on potential impact analysis."

        return base_reasoning + confidence_text + severity_text

    def _estimate_downtime(self, anomaly: AnomalyDetection) -> float:
        """Estimate potential downtime from anomaly"""
        severity_multipliers = {
            "LOW": 0.5,
            "MEDIUM": 2.0,
            "HIGH": 8.0,
            "CRITICAL": 24.0,
        }
        base_downtime = severity_multipliers.get(anomaly.severity, 2.0)
        confidence_multiplier = 0.5 + (anomaly.confidence * 0.5)
        return base_downtime * confidence_multiplier

    def _estimate_cost_impact(self, anomaly: AnomalyDetection) -> float:
        """Estimate cost impact of anomaly"""
        downtime_hours = self._estimate_downtime(anomaly)
        cost_per_hour = random.uniform(1000, 5000)  # Varies by equipment type
        return downtime_hours * cost_per_hour

    def _assess_safety_risk(self, anomaly: AnomalyDetection) -> str:
        """Assess safety risk level"""
        high_risk_types = ["threshold_exceeded", "rapid_change"]
        critical_sensors = ["temperature", "pressure", "vibration"]

        if anomaly.anomaly_type in high_risk_types and any(
            sensor in anomaly.sensor_id.lower() for sensor in critical_sensors
        ):
            return "HIGH"
        elif anomaly.severity in ["CRITICAL", "HIGH"]:
            return "MEDIUM"
        else:
            return "LOW"

    def _generate_recommended_actions(self, anomaly: AnomalyDetection) -> List[str]:
        """Generate recommended actions based on anomaly type"""
        action_templates = {
            "statistical_outlier": [
                "Verify sensor calibration and data quality",
                "Conduct equipment inspection for unusual wear patterns",
                "Review recent maintenance history and operating conditions",
            ],
            "rapid_change": [
                "Immediately investigate cause of sudden performance change",
                "Check for recent operational changes or environmental factors",
                "Monitor equipment continuously for stability",
            ],
            "threshold_exceeded": [
                "Initiate emergency shutdown procedures if safe to do so",
                "Dispatch qualified technician for immediate assessment",
                "Implement temporary mitigation measures to prevent damage",
            ],
            "threshold_below_minimum": [
                "Check equipment settings and operating parameters",
                "Verify input materials and supply conditions",
                "Schedule diagnostic testing to identify root cause",
            ],
        }

        base_actions = action_templates.get(
            anomaly.anomaly_type, ["Investigate anomaly and take corrective action"]
        )

        # Add severity-specific actions
        if anomaly.severity == "CRITICAL":
            base_actions.insert(
                0, "IMMEDIATE ACTION REQUIRED: Stop operation if safe to do so"
            )
        elif anomaly.severity == "HIGH":
            base_actions.insert(0, "Escalate to maintenance supervisor within 1 hour")

        return base_actions

    async def _escalate_alert(self, alert: IntelligentAlert):
        """Auto-escalate critical alerts"""
        logger.critical(
            f"üö® AUTO-ESCALATION: {alert.title} - Equipment {alert.equipment_id}"
        )
        # In a real system, this would trigger notifications, work orders, etc.

    async def _initialize_anomaly_detector(
        self, equipment_id: str, sensor_metadata: Dict[str, Any]
    ):
        """Initialize anomaly detection for equipment"""
        # This would initialize ML models in a production system
        self.anomaly_detectors[equipment_id] = {
            "initialized_at": datetime.now(),
            "model_type": "statistical_threshold",
            "calibration_period": 100,  # Number of readings for calibration
            "sensitivity": sensor_metadata.get("anomaly_sensitivity", 0.8),
        }

        logger.info(f"‚úÖ Anomaly detector initialized for equipment {equipment_id}")

    async def get_system_status(self) -> Dict[str, Any]:
        """
        üìä Get comprehensive system status and metrics
        """
        return {
            "system_health": {
                "registered_sensors": len(self.sensor_registry),
                "active_equipment": len(self.data_buffer),
                "total_data_points": self.metrics["data_points_processed"],
                "anomalies_detected": self.metrics["anomalies_detected"],
                "alerts_generated": self.metrics["alerts_generated"],
                "average_processing_latency_ms": round(
                    self.metrics["processing_latency_ms"], 2
                ),
            },
            "recent_activity": {
                "last_24h_alerts": len(
                    [
                        a
                        for a in self.alert_history
                        if (datetime.now() - a.timestamp).days < 1
                    ]
                ),
                "critical_alerts_active": len(
                    [a for a in self.alert_history[-10:] if a.priority == "CRITICAL"]
                ),
                "equipment_with_issues": len(
                    [
                        e
                        for e in self.health_snapshots.values()
                        if e.maintenance_urgency in ["HIGH", "CRITICAL"]
                    ]
                ),
            },
            "ai_performance": {
                "detection_accuracy": round(
                    self.metrics.get("accuracy_score", 0.85), 2
                ),
                "false_positive_rate": round(random.uniform(0.02, 0.08), 3),
                "processing_efficiency": "95.2%",
            },
        }

    async def get_equipment_dashboard_data(self, equipment_id: str) -> Dict[str, Any]:
        """
        üìä Get dashboard data for specific equipment
        """
        health_snapshot = self.health_snapshots.get(equipment_id)
        recent_readings = list(self.data_buffer.get(equipment_id, []))

        return {
            "equipment_id": equipment_id,
            "health_snapshot": asdict(health_snapshot) if health_snapshot else None,
            "recent_readings_count": len(recent_readings),
            "active_sensors": len(
                [
                    s
                    for s in self.sensor_registry.values()
                    if s["equipment_id"] == equipment_id
                ]
            ),
            "recent_alerts": [
                asdict(a) for a in self.alert_history if a.equipment_id == equipment_id
            ][-5:],
            "performance_trends": await self._generate_performance_trends(equipment_id),
        }

    async def _generate_performance_trends(
        self, equipment_id: str
    ) -> Dict[str, List[float]]:
        """Generate performance trend data for dashboard"""
        recent_readings = list(self.data_buffer.get(equipment_id, []))
        trends = {}

        # Group by reading type and generate trends
        readings_by_type = defaultdict(list)
        for reading in recent_readings[-50:]:  # Last 50 readings
            readings_by_type[reading.reading_type].append(reading.value)

        for reading_type, values in readings_by_type.items():
            if len(values) >= 5:
                # Create simple trend (last 10 values)
                trends[reading_type] = values[-10:]

        return trends


# Global instance
_autonomous_engine = None


async def get_autonomous_data_engine() -> AutonomousDataEngine:
    """Get global autonomous data engine instance"""
    global _autonomous_engine
    if _autonomous_engine is None:
        _autonomous_engine = AutonomousDataEngine()
        logger.info("ü§ñ Autonomous Data Engine initialized")
    return _autonomous_engine
