<!-- AI Assistant Widget with Microphone and Camera -->
<style>
    /* Hover bounce animation for AI widget */
    @keyframes widget-hover-bounce {
        0%, 100% { transform: scale(1.1) translateY(0); }
        50% { transform: scale(1.1) translateY(-8px); }
    }
    #ai-widget-toggle:hover {
        animation: widget-hover-bounce 0.6s ease-in-out;
    }
</style>
<div class="ai-assistant-widget fixed bottom-8 right-8 z-[999999]">
    <!-- Main AI Widget Button -->
    <div id="ai-widget-toggle" class="bg-gradient-to-r from-blue-500 to-purple-600 hover:from-blue-600 hover:to-purple-700 text-white rounded-full w-20 h-20 flex items-center justify-center cursor-pointer shadow-2xl transition-all duration-300 hover:scale-110 border-4 border-white relative">
        <i class="fas fa-robot text-2xl"></i>
        <!-- Subtle indicator dot -->
        <div class="absolute -top-1 -right-1 w-4 h-4 bg-green-500 rounded-full border-2 border-white"></div>
    </div>

    <!-- Expanded AI Widget Panel -->
    <div id="ai-widget-panel" class="hidden absolute bottom-24 right-0 bg-white rounded-2xl shadow-2xl border border-gray-200 w-96 max-w-[calc(100vw-4rem)] overflow-hidden z-[1000000]">
        <!-- Header -->
        <div class="bg-gradient-to-r from-blue-500 to-purple-600 text-white p-4">
            <div class="flex items-center justify-between">
                <div class="flex items-center space-x-3">
                    <div class="w-10 h-10 bg-white bg-opacity-20 rounded-full flex items-center justify-center">
                        <i class="fas fa-brain text-lg"></i>
                    </div>
                    <div>
                        <h3 class="font-semibold text-lg">AI Assistant</h3>
                        <p class="text-sm opacity-90">Voice & Vision Commands</p>
                    </div>
                </div>
                <button id="ai-widget-close" class="text-white hover:bg-white hover:bg-opacity-20 rounded-full p-2 transition-colors">
                    <i class="fas fa-times"></i>
                </button>
            </div>
        </div>

        <!-- Content Area -->
        <div class="p-4 max-h-96 overflow-y-auto">
            <!-- Voice Commands Section -->
            <div class="mb-4">
                <h4 class="font-semibold text-gray-800 mb-3 flex items-center">
                    <i class="fas fa-microphone text-blue-500 mr-2"></i>
                    Voice Commands
                </h4>
                <div class="grid grid-cols-2 gap-2">
                    <button id="voice-record-btn" class="voice-btn bg-red-500 hover:bg-red-600 text-white py-2 px-3 rounded-lg text-sm font-medium transition-colors flex items-center justify-center">
                        <i class="fas fa-circle text-xs mr-2"></i>
                        <span id="voice-status">Start Recording</span>
                    </button>
                    <button id="voice-stop-btn" class="bg-gray-500 hover:bg-gray-600 text-white py-2 px-3 rounded-lg text-sm font-medium transition-colors hidden">
                        <i class="fas fa-stop text-xs mr-2"></i>
                        Stop
                    </button>
                </div>
                <div id="voice-transcript" class="mt-2 p-2 bg-gray-50 rounded-lg text-sm text-gray-700 min-h-[40px] hidden"></div>
            </div>

            <!-- Camera Section -->
            <div class="mb-4">
                <h4 class="font-semibold text-gray-800 mb-3 flex items-center">
                    <i class="fas fa-camera text-green-500 mr-2"></i>
                    Image Recognition
                </h4>
                <div class="space-y-2">
                    <div class="grid grid-cols-2 gap-2">
                        <button id="camera-capture-btn" class="bg-green-500 hover:bg-green-600 text-white py-2 px-3 rounded-lg text-sm font-medium transition-colors flex items-center justify-center">
                            <i class="fas fa-camera text-xs mr-2"></i>
                            <span id="camera-status">Take Photo</span>
                        </button>
                        <label for="photo-upload" class="bg-blue-500 hover:bg-blue-600 text-white py-2 px-3 rounded-lg text-sm font-medium transition-colors flex items-center justify-center cursor-pointer">
                            <i class="fas fa-upload text-xs mr-2"></i>
                            Upload Photo
                        </label>
                        <input type="file" id="photo-upload" accept="image/*" class="hidden">
                    </div>
                    <video id="camera-preview" class="w-full rounded-lg hidden" autoplay playsinline></video>
                    <canvas id="camera-canvas" class="hidden"></canvas>
                    <div id="image-analysis" class="p-2 bg-green-50 rounded-lg text-sm text-green-700 min-h-[40px] hidden"></div>
                </div>
            </div>

            <!-- Chat Input Area -->
            <div class="mb-4">
                <h4 class="font-semibold text-gray-800 mb-3 flex items-center">
                    <i class="fas fa-keyboard text-blue-500 mr-2"></i>
                    Ask AI Assistant
                </h4>
                <div class="flex gap-2">
                    <input type="text" id="ai-chat-input"
                           placeholder="Type your question or command..."
                           class="flex-1 px-3 py-2 border border-gray-300 rounded-lg text-sm focus:outline-none focus:ring-2 focus:ring-blue-500 focus:border-transparent"
                           onkeypress="if(event.key==='Enter') window.aiAssistantWidget?.processVoiceCommand(this.value)">
                    <button id="ai-send-btn"
                            onclick="window.aiAssistantWidget?.processVoiceCommand(document.getElementById('ai-chat-input').value)"
                            class="bg-blue-500 hover:bg-blue-600 text-white px-4 py-2 rounded-lg text-sm font-medium transition-colors">
                        <i class="fas fa-paper-plane"></i>
                    </button>
                </div>
            </div>

            <!-- AI Response Area -->
            <div class="mb-4">
                <h4 class="font-semibold text-gray-800 mb-3 flex items-center">
                    <i class="fas fa-robot text-purple-500 mr-2"></i>
                    AI Response
                </h4>
                <div id="ai-response" class="p-3 bg-purple-50 rounded-lg text-sm text-purple-700 min-h-[60px] flex items-center justify-center text-gray-500">
                    <span>AI assistant ready to help...</span>
                </div>
            </div>

            <!-- Quick Commands -->
            <div class="mb-4">
                <h4 class="font-semibold text-gray-800 mb-3">Quick Commands</h4>
                <div class="grid grid-cols-2 gap-2">
                    <button class="quick-cmd bg-blue-100 hover:bg-blue-200 text-blue-700 py-2 px-3 rounded-lg text-xs font-medium transition-colors" data-command="Show me the analytics dashboard">
                        üìä Analytics
                    </button>
                    <button class="quick-cmd bg-green-100 hover:bg-green-200 text-green-700 py-2 px-3 rounded-lg text-xs font-medium transition-colors" data-command="Create a new work order">
                        üìù New Work Order
                    </button>
                    <button class="quick-cmd bg-yellow-100 hover:bg-yellow-200 text-yellow-700 py-2 px-3 rounded-lg text-xs font-medium transition-colors" data-command="Check equipment status">
                        ‚öôÔ∏è Equipment Status
                    </button>
                    <button class="quick-cmd bg-red-100 hover:bg-red-200 text-red-700 py-2 px-3 rounded-lg text-xs font-medium transition-colors" data-command="Report an issue">
                        üö® Report Issue
                    </button>
                </div>
            </div>

            <!-- Equipment Diagnosis Quick Actions -->
            <div class="mb-4">
                <h4 class="font-semibold text-gray-800 mb-3 flex items-center">
                    <i class="fas fa-wrench text-orange-500 mr-2"></i>
                    Equipment Diagnosis
                </h4>
                <div class="grid grid-cols-2 gap-2">
                    <button class="diagnosis-cmd bg-orange-100 hover:bg-orange-200 text-orange-700 py-2 px-3 rounded-lg text-xs font-medium transition-colors" data-action="diagnose-equipment">
                        üîç Diagnose Equipment
                    </button>
                    <button class="diagnosis-cmd bg-purple-100 hover:bg-purple-200 text-purple-700 py-2 px-3 rounded-lg text-xs font-medium transition-colors" data-action="identify-part">
                        üîß Identify Part
                    </button>
                    <button class="diagnosis-cmd bg-teal-100 hover:bg-teal-200 text-teal-700 py-2 px-3 rounded-lg text-xs font-medium transition-colors" data-action="read-label">
                        üìÑ Read Label (OCR)
                    </button>
                    <button class="diagnosis-cmd bg-indigo-100 hover:bg-indigo-200 text-indigo-700 py-2 px-3 rounded-lg text-xs font-medium transition-colors" data-action="find-manual">
                        üìö Find Manual
                    </button>
                </div>
            </div>
        </div>

        <!-- Status Bar -->
        <div class="bg-gray-50 px-4 py-2 border-t border-gray-200">
            <div class="flex items-center justify-between text-xs text-gray-600">
                <div class="flex items-center space-x-4">
                    <span id="mic-status" class="flex items-center">
                        <i class="fas fa-microphone text-gray-400 mr-1"></i>
                        Ready
                    </span>
                    <span id="camera-status-widget" class="flex items-center">
                        <i class="fas fa-camera text-gray-400 mr-1"></i>
                        Ready
                    </span>
                </div>
                <span id="ai-status" class="flex items-center">
                    <i class="fas fa-circle text-green-500 mr-1"></i>
                    Online
                </span>
            </div>
        </div>
    </div>
</div>

<!-- AI Assistant Widget JavaScript -->
<script>
class AIAssistantWidget {
    constructor() {
        this.isRecording = false;
        this.mediaRecorder = null;
        this.audioChunks = [];
        this.stream = null;
        this.cameraStream = null;
        this.recognition = null;

        this.init();
    }

    init() {
        // Initialize speech recognition
        this.initSpeechRecognition();

        // Bind event listeners
        this.bindEvents();

        console.log('ü§ñ AI Assistant Widget initialized');
    }

    initSpeechRecognition() {
        // Check for browser support
        const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;

        if (SpeechRecognition) {
            this.recognition = new SpeechRecognition();
            this.recognition.continuous = false;
            this.recognition.interimResults = false;
            this.recognition.lang = 'en-US';

            this.recognition.onstart = () => {
                this.updateVoiceStatus('listening', 'üé§ Listening...');
                this.showTranscript('Listening for your command...');
            };

            this.recognition.onresult = (event) => {
                const transcript = event.results[0][0].transcript;
                this.showTranscript(`"${transcript}"`);
                this.processVoiceCommand(transcript);
            };

            this.recognition.onerror = (event) => {
                console.error('Speech recognition error:', event.error);
                this.updateVoiceStatus('error', 'Error');
                this.showTranscript('Speech recognition error. Please try again.');
            };

            this.recognition.onend = () => {
                this.updateVoiceStatus('ready', 'Start Recording');
                if (!this.isRecording) {
                    this.hideTranscript();
                }
            };
        } else {
            console.warn('Speech recognition not supported in this browser');
            this.showTranscript('Speech recognition not supported in this browser');
        }
    }

    bindEvents() {
        // Widget toggle
        document.getElementById('ai-widget-toggle').addEventListener('click', () => {
            this.toggleWidget();
        });

        // Close button
        document.getElementById('ai-widget-close').addEventListener('click', () => {
            this.closeWidget();
        });

        // Voice recording buttons
        document.getElementById('voice-record-btn').addEventListener('click', () => {
            this.startVoiceRecording();
        });

        document.getElementById('voice-stop-btn').addEventListener('click', () => {
            this.stopVoiceRecording();
        });

        // Camera button
        document.getElementById('camera-capture-btn').addEventListener('click', () => {
            this.captureImage();
        });

        // Photo upload
        document.getElementById('photo-upload').addEventListener('change', (e) => {
            this.handlePhotoUpload(e);
        });

        // Quick commands
        document.querySelectorAll('.quick-cmd').forEach(btn => {
            btn.addEventListener('click', (e) => {
                const command = e.target.dataset.command;
                this.processVoiceCommand(command);
            });
        });

        // Equipment diagnosis commands
        document.querySelectorAll('.diagnosis-cmd').forEach(btn => {
            btn.addEventListener('click', (e) => {
                const action = e.target.dataset.action;
                this.handleDiagnosisAction(action);
            });
        });

        // Click outside to close
        document.addEventListener('click', (e) => {
            const widget = document.querySelector('.ai-assistant-widget');
            const panel = document.getElementById('ai-widget-panel');
            const toggle = document.getElementById('ai-widget-toggle');

            if (!widget.contains(e.target) && panel.classList.contains('block')) {
                this.closeWidget();
            }
        });
    }

    toggleWidget() {
        const panel = document.getElementById('ai-widget-panel');
        const toggle = document.getElementById('ai-widget-toggle');

        if (panel.classList.contains('hidden')) {
            panel.classList.remove('hidden');
            panel.classList.add('block');
            toggle.innerHTML = '<i class="fas fa-times text-xl"></i>';
        } else {
            this.closeWidget();
        }
    }

    closeWidget() {
        const panel = document.getElementById('ai-widget-panel');
        const toggle = document.getElementById('ai-widget-toggle');

        panel.classList.add('hidden');
        panel.classList.remove('block');
        toggle.innerHTML = '<i class="fas fa-robot text-xl"></i>';
    }

    updateVoiceStatus(status, text) {
        const statusEl = document.getElementById('mic-status');
        const btnText = document.getElementById('voice-status');

        if (status === 'listening') {
            statusEl.innerHTML = '<i class="fas fa-microphone text-red-500 mr-1 animate-pulse"></i>Listening';
            btnText.textContent = 'Listening...';
        } else if (status === 'processing') {
            statusEl.innerHTML = '<i class="fas fa-cog text-blue-500 mr-1 animate-spin"></i>Processing';
            btnText.textContent = 'Processing...';
        } else if (status === 'error') {
            statusEl.innerHTML = '<i class="fas fa-exclamation-triangle text-red-500 mr-1"></i>Error';
            btnText.textContent = 'Error';
        } else {
            statusEl.innerHTML = '<i class="fas fa-microphone text-gray-400 mr-1"></i>Ready';
            btnText.textContent = 'Start Recording';
        }
    }

    showTranscript(text) {
        const transcriptEl = document.getElementById('voice-transcript');
        transcriptEl.textContent = text;
        transcriptEl.classList.remove('hidden');
    }

    hideTranscript() {
        const transcriptEl = document.getElementById('voice-transcript');
        transcriptEl.classList.add('hidden');
    }

    startVoiceRecording() {
        if (this.recognition) {
            this.isRecording = true;
            document.getElementById('voice-record-btn').classList.add('hidden');
            document.getElementById('voice-stop-btn').classList.remove('hidden');

            try {
                this.recognition.start();
            } catch (error) {
                console.error('Error starting speech recognition:', error);
                this.showTranscript('Error starting voice recognition');
                this.resetVoiceButtons();
            }
        } else {
            this.showTranscript('Speech recognition not supported');
        }
    }

    stopVoiceRecording() {
        if (this.recognition && this.isRecording) {
            this.recognition.stop();
            this.isRecording = false;
            this.resetVoiceButtons();
        }
    }

    resetVoiceButtons() {
        document.getElementById('voice-record-btn').classList.remove('hidden');
        document.getElementById('voice-stop-btn').classList.add('hidden');
        this.updateVoiceStatus('ready', 'Start Recording');
    }

    async captureImage() {
        const video = document.getElementById('camera-preview');
        const canvas = document.getElementById('camera-canvas');
        const analysisEl = document.getElementById('image-analysis');
        const cameraBtn = document.getElementById('camera-capture-btn');
        const cameraStatus = document.getElementById('camera-status');

        try {
            // Request camera access
            this.cameraStream = await navigator.mediaDevices.getUserMedia({
                video: { facingMode: 'environment' },
                audio: false
            });

            video.srcObject = this.cameraStream;
            video.classList.remove('hidden');
            cameraStatus.textContent = 'Camera Active';

            // Wait for video to load
            await new Promise(resolve => {
                video.onloadedmetadata = resolve;
            });

            // Set canvas size to match video
            canvas.width = video.videoWidth;
            canvas.height = video.videoHeight;

            // Draw current frame to canvas
            const ctx = canvas.getContext('2d');
            ctx.drawImage(video, 0, 0);

            // Stop camera stream
            this.cameraStream.getTracks().forEach(track => track.stop());
            video.classList.add('hidden');
            cameraStatus.textContent = 'Processing...';

            // Convert to base64 for analysis
            const imageData = canvas.toDataURL('image/jpeg', 0.8);

            // Analyze image
            await this.analyzeImage(imageData);

        } catch (error) {
            console.error('Camera error:', error);
            analysisEl.textContent = 'Camera access denied or not available';
            analysisEl.classList.remove('hidden');
            cameraStatus.textContent = 'Camera Error';
        }
    }

    async analyzeImage(imageData, context = 'equipment_inspection') {
        const analysisEl = document.getElementById('image-analysis');
        const cameraStatus = document.getElementById('camera-status');
        const responseEl = document.getElementById('ai-response');

        try {
            cameraStatus.textContent = 'Analyzing...';
            responseEl.innerHTML = '<div class="flex items-center"><i class="fas fa-cog animate-spin mr-2"></i>Analyzing image...</div>';

            // Send to AI for analysis
            const response = await fetch('/ai/analyze-image', {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json',
                },
                body: JSON.stringify({
                    image: imageData,
                    context: context
                })
            });

            if (response.ok) {
                const result = await response.json();
                const analysis = result.analysis || 'Image analyzed successfully';

                analysisEl.textContent = analysis;

                // Also show in AI response area with more details
                responseEl.innerHTML = `
                    <div class="space-y-2">
                        <div class="font-medium text-purple-800">Image Analysis Complete:</div>
                        <div class="text-sm">${analysis}</div>
                        ${result.image_size ? `<div class="text-xs text-gray-600 mt-1">Image: ${result.image_size}</div>` : ''}
                        ${result.context ? `<div class="text-xs text-gray-600">Context: ${result.context}</div>` : ''}
                    </div>
                `;
            } else {
                const errorMsg = 'Analysis failed - please try again';
                analysisEl.textContent = errorMsg;
                responseEl.innerHTML = `<div class="text-red-600">‚ùå ${errorMsg}</div>`;
            }

        } catch (error) {
            console.error('Image analysis error:', error);
            const errorMsg = 'Error analyzing image';
            analysisEl.textContent = errorMsg;
            responseEl.innerHTML = `<div class="text-red-600">‚ùå ${errorMsg}</div>`;
        }

        analysisEl.classList.remove('hidden');
        cameraStatus.textContent = 'Take Photo';
    }

    async processVoiceCommand(command, additionalContext = {}) {
        // Skip empty commands
        if (!command || !command.trim()) {
            return;
        }

        console.log('üé§ Processing command:', command);

        // Clear the text input if it exists
        const chatInput = document.getElementById('ai-chat-input');
        if (chatInput) {
            chatInput.value = '';
        }

        this.updateVoiceStatus('processing', 'Processing...');

        const responseEl = document.getElementById('ai-response');
        responseEl.innerHTML = '<div class="flex items-center"><i class="fas fa-cog animate-spin mr-2"></i>Processing your request...</div>';

        try {
            // Detect if command is equipment-related for better context
            const commandLower = command.toLowerCase();
            let contextType = 'general';

            if (commandLower.includes('diagnose') || commandLower.includes('equipment') || commandLower.includes('issue')) {
                contextType = 'equipment_diagnosis';
            } else if (commandLower.includes('part') || commandLower.includes('component')) {
                contextType = 'part_recognition';
            } else if (commandLower.includes('manual') || commandLower.includes('documentation')) {
                contextType = 'find_manual';
            } else if (commandLower.includes('troubleshoot') || commandLower.includes('fix')) {
                contextType = 'troubleshooting';
            }

            // Send command to AI assistant
            const response = await fetch('/ai/process-command', {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json',
                },
                body: JSON.stringify({
                    command: command,
                    source: 'voice_widget',
                    context: window.location.pathname,
                    context_type: contextType,
                    ...additionalContext
                })
            });

            if (response.ok) {
                const result = await response.json();

                // Display AI response
                responseEl.innerHTML = `
                    <div class="space-y-2">
                        <div class="font-medium text-purple-800">AI Response:</div>
                        <div class="text-sm">${result.response || 'Command processed successfully'}</div>
                        ${result.action ? `<div class="text-xs text-gray-600 mt-1">Action: ${result.action}</div>` : ''}
                    </div>
                `;

                // Execute any suggested actions
                if (result.action === 'navigate') {
                    if (result.target) {
                        window.location.href = result.target;
                    }
                } else if (result.action === 'modal') {
                    // Could trigger modal opening here
                    console.log('Modal action requested:', result.modal);
                }

            } else {
                responseEl.innerHTML = '<div class="text-red-600">‚ùå Error processing command</div>';
            }

        } catch (error) {
            console.error('Voice command processing error:', error);
            responseEl.innerHTML = '<div class="text-red-600">‚ùå Network error - please try again</div>';
        }

        this.updateVoiceStatus('ready', 'Start Recording');
    }

    async handlePhotoUpload(event) {
        const file = event.target.files[0];
        if (!file) return;

        const analysisEl = document.getElementById('image-analysis');
        const cameraStatus = document.getElementById('camera-status');

        try {
            cameraStatus.textContent = 'Processing...';
            analysisEl.textContent = 'Reading uploaded image...';
            analysisEl.classList.remove('hidden');

            // Convert file to base64
            const reader = new FileReader();
            reader.onload = async (e) => {
                const imageData = e.target.result;

                // Analyze image
                await this.analyzeImage(imageData);
            };
            reader.readAsDataURL(file);

        } catch (error) {
            console.error('Photo upload error:', error);
            analysisEl.textContent = 'Error processing uploaded photo';
            analysisEl.classList.remove('hidden');
            cameraStatus.textContent = 'Upload Photo';
        }
    }

    async handleDiagnosisAction(action) {
        console.log('üîß Diagnosis action:', action);

        const responseEl = document.getElementById('ai-response');

        switch(action) {
            case 'diagnose-equipment':
                await this.diagnoseEquipment();
                break;
            case 'identify-part':
                await this.identifyPart();
                break;
            case 'read-label':
                await this.readLabel();
                break;
            case 'find-manual':
                await this.findManual();
                break;
            default:
                responseEl.innerHTML = '<div class="text-gray-600">Unknown action</div>';
        }
    }

    async diagnoseEquipment() {
        const responseEl = document.getElementById('ai-response');
        responseEl.innerHTML = '<div class="text-blue-600">üì∑ Please take a photo of the equipment to diagnose...</div>';

        // Trigger camera with equipment diagnosis context
        try {
            const video = document.getElementById('camera-preview');
            const canvas = document.getElementById('camera-canvas');
            const cameraStatus = document.getElementById('camera-status');

            this.cameraStream = await navigator.mediaDevices.getUserMedia({
                video: { facingMode: 'environment' },
                audio: false
            });

            video.srcObject = this.cameraStream;
            video.classList.remove('hidden');
            cameraStatus.textContent = 'Camera Active';

            await new Promise(resolve => {
                video.onloadedmetadata = resolve;
            });

            await new Promise(resolve => setTimeout(resolve, 1000));

            canvas.width = video.videoWidth;
            canvas.height = video.videoHeight;

            const ctx = canvas.getContext('2d');
            ctx.drawImage(video, 0, 0);

            this.cameraStream.getTracks().forEach(track => track.stop());
            video.classList.add('hidden');

            const imageData = canvas.toDataURL('image/jpeg', 0.8);
            await this.analyzeImage(imageData, 'equipment_diagnosis');

        } catch (error) {
            console.error('Equipment diagnosis error:', error);
            responseEl.innerHTML = '<div class="text-red-600">‚ùå Camera access denied or error occurred</div>';
        }
    }

    async identifyPart() {
        const responseEl = document.getElementById('ai-response');
        responseEl.innerHTML = '<div class="text-blue-600">üì∑ Please take a photo of the part to identify...</div>';

        try {
            const video = document.getElementById('camera-preview');
            const canvas = document.getElementById('camera-canvas');
            const cameraStatus = document.getElementById('camera-status');

            this.cameraStream = await navigator.mediaDevices.getUserMedia({
                video: { facingMode: 'environment' },
                audio: false
            });

            video.srcObject = this.cameraStream;
            video.classList.remove('hidden');
            cameraStatus.textContent = 'Camera Active';

            await new Promise(resolve => {
                video.onloadedmetadata = resolve;
            });

            await new Promise(resolve => setTimeout(resolve, 1000));

            canvas.width = video.videoWidth;
            canvas.height = video.videoHeight;

            const ctx = canvas.getContext('2d');
            ctx.drawImage(video, 0, 0);

            this.cameraStream.getTracks().forEach(track => track.stop());
            video.classList.add('hidden');

            const imageData = canvas.toDataURL('image/jpeg', 0.8);
            await this.analyzeImage(imageData, 'part_recognition');

        } catch (error) {
            console.error('Part identification error:', error);
            responseEl.innerHTML = '<div class="text-red-600">‚ùå Camera access denied or error occurred</div>';
        }
    }

    async readLabel() {
        const responseEl = document.getElementById('ai-response');
        responseEl.innerHTML = '<div class="text-blue-600">üì∑ Please take a photo of the label to read...</div>';

        try {
            const video = document.getElementById('camera-preview');
            const canvas = document.getElementById('camera-canvas');
            const cameraStatus = document.getElementById('camera-status');

            this.cameraStream = await navigator.mediaDevices.getUserMedia({
                video: { facingMode: 'environment' },
                audio: false
            });

            video.srcObject = this.cameraStream;
            video.classList.remove('hidden');
            cameraStatus.textContent = 'Camera Active';

            await new Promise(resolve => {
                video.onloadedmetadata = resolve;
            });

            await new Promise(resolve => setTimeout(resolve, 1000));

            canvas.width = video.videoWidth;
            canvas.height = video.videoHeight;

            const ctx = canvas.getContext('2d');
            ctx.drawImage(video, 0, 0);

            this.cameraStream.getTracks().forEach(track => track.stop());
            video.classList.add('hidden');

            const imageData = canvas.toDataURL('image/jpeg', 0.8);
            await this.analyzeImage(imageData, 'text_extraction');

        } catch (error) {
            console.error('Label reading error:', error);
            responseEl.innerHTML = '<div class="text-red-600">‚ùå Camera access denied or error occurred</div>';
        }
    }

    async findManual() {
        const responseEl = document.getElementById('ai-response');

        const equipmentName = prompt('Enter equipment name or model number:');

        if (!equipmentName) {
            responseEl.innerHTML = '<div class="text-gray-600">Manual search cancelled</div>';
            return;
        }

        responseEl.innerHTML = '<div class="flex items-center"><i class="fas fa-search animate-spin mr-2"></i>Searching for manual...</div>';

        await this.processVoiceCommand(`Find manual for ${equipmentName}`, {
            context_type: 'find_manual',
            equipment_name: equipmentName
        });
    }
}

// Initialize widget when DOM is loaded
document.addEventListener('DOMContentLoaded', () => {
    window.aiAssistantWidget = new AIAssistantWidget();
});

// Export for global access
window.AIAssistantWidget = AIAssistantWidget;
</script>

<style>
/* ============================================
   AI ASSISTANT WIDGET - HIGH CONTRAST STYLES
   ============================================ */

/* Base widget styling */
.ai-assistant-widget {
    font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
}

/* Force white background with dark text for widget panel */
#ai-widget-panel {
    background-color: #ffffff !important;
    color: #1f2937 !important;
}

/* Ensure all headings are dark and visible */
#ai-widget-panel h4 {
    color: #1f2937 !important;
    font-weight: 600 !important;
}

/* Make sure text inputs are readable */
#ai-chat-input {
    background-color: #ffffff !important;
    color: #1f2937 !important;
    border: 1px solid #d1d5db !important;
}

#ai-chat-input::placeholder {
    color: #9ca3af !important;
}

/* Voice transcript area - high contrast */
#voice-transcript {
    background-color: #f3f4f6 !important;
    color: #1f2937 !important;
    border: 1px solid #e5e7eb !important;
}

/* Image analysis area - high contrast */
#image-analysis {
    background-color: #ecfdf5 !important;
    color: #065f46 !important;
    border: 1px solid #6ee7b7 !important;
}

/* AI Response area - high contrast purple */
#ai-response {
    background-color: #faf5ff !important;
    color: #6b21a8 !important;
    border: 1px solid #e9d5ff !important;
}

#ai-response span {
    color: #6b21a8 !important;
}

#ai-response .text-purple-800 {
    color: #581c87 !important;
}

#ai-response .text-sm {
    color: #6b21a8 !important;
}

#ai-response .text-gray-600 {
    color: #4b5563 !important;
}

/* Make all icons in headings visible */
#ai-widget-panel h4 i {
    opacity: 1 !important;
}

/* Status bar - high contrast */
#ai-widget-panel > div:last-child {
    background-color: #f9fafb !important;
    color: #4b5563 !important;
    border-top: 1px solid #e5e7eb !important;
}

#mic-status, #camera-status-widget, #ai-status {
    color: #4b5563 !important;
}

/* Button text visibility */
#voice-record-btn, #voice-stop-btn, #camera-capture-btn, #ai-send-btn {
    color: #ffffff !important;
}

#voice-status {
    color: #ffffff !important;
}

/* Make sure all button text is white on colored backgrounds */
button.bg-red-500, button.bg-gray-500, button.bg-green-500, button.bg-blue-500 {
    color: #ffffff !important;
}

label.bg-blue-500 {
    color: #ffffff !important;
}

/* Ensure quick command text colors are strong and readable */
.quick-cmd.bg-blue-100 {
    background-color: #dbeafe !important;
}
.quick-cmd.text-blue-700 {
    color: #1e40af !important;
}

.quick-cmd.bg-green-100 {
    background-color: #dcfce7 !important;
}
.quick-cmd.text-green-700 {
    color: #15803d !important;
}

.quick-cmd.bg-yellow-100 {
    background-color: #fef3c7 !important;
}
.quick-cmd.text-yellow-700 {
    color: #a16207 !important;
}

.quick-cmd.bg-red-100 {
    background-color: #fee2e2 !important;
}
.quick-cmd.text-red-700 {
    color: #b91c1c !important;
}

/* Ensure diagnosis command text colors are strong and readable */
.diagnosis-cmd.bg-orange-100 {
    background-color: #ffedd5 !important;
}
.diagnosis-cmd.text-orange-700 {
    color: #c2410c !important;
}

.diagnosis-cmd.bg-purple-100 {
    background-color: #f3e8ff !important;
}
.diagnosis-cmd.text-purple-700 {
    color: #7e22ce !important;
}

.diagnosis-cmd.bg-teal-100 {
    background-color: #ccfbf1 !important;
}
.diagnosis-cmd.text-teal-700 {
    color: #0f766e !important;
}

.diagnosis-cmd.bg-indigo-100 {
    background-color: #e0e7ff !important;
}
.diagnosis-cmd.text-indigo-700 {
    color: #4338ca !important;
}

/* ============================================
   ANIMATIONS AND INTERACTIONS
   ============================================ */

.voice-btn.recording {
    animation: pulse 1.5s infinite;
}

@keyframes pulse {
    0%, 100% { transform: scale(1); }
    50% { transform: scale(1.05); }
}

.quick-cmd {
    transition: all 0.2s ease;
}

.quick-cmd:hover {
    transform: translateY(-1px);
    box-shadow: 0 2px 8px rgba(0,0,0,0.1);
}

.diagnosis-cmd {
    transition: all 0.2s ease;
}

.diagnosis-cmd:hover {
    transform: translateY(-1px);
    box-shadow: 0 2px 8px rgba(0,0,0,0.1);
}

/* Mobile responsiveness */
@media (max-width: 768px) {
    .ai-assistant-widget {
        bottom: 2rem !important;
        right: 2rem !important;
    }

    .ai-assistant-widget .fixed.bottom-8.right-8 > div:last-child {
        right: 1rem;
        left: 1rem;
        width: auto;
        max-width: none;
        bottom: 6rem;
    }

    .ai-assistant-widget #ai-widget-panel {
        width: calc(100vw - 4rem) !important;
        max-width: none !important;
    }
}

/* Ensure AI widget is always on top */
.ai-assistant-widget {
    z-index: 999999 !important;
}

.ai-assistant-widget * {
    z-index: inherit;
}

/* Make sure no other elements can cover the AI widget */
body > *:not(.ai-assistant-widget) {
    z-index: auto !important;
}
</style>
