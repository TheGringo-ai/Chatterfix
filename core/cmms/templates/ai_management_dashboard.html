<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ChatterFix AI Management Dashboard</title>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700;800&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="chatterfix_unified_theme.css">
    <style>
        /* AI Dashboard specific overrides */
        .header {
            text-align: center;
            padding: 1.5rem 2rem;
        }
        
        .header h1 {
            font-size: 2.5rem;
            background: var(--chatterfix-gradient-accent);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            background-clip: text;
            margin-bottom: 0.5rem;
            font-weight: 700;
        }
        
        .subtitle {
            color: var(--chatterfix-text-secondary);
            font-size: 1.1rem;
        }
        
        .dashboard {
            padding: 2rem;
            max-width: 1400px;
            margin: 0 auto;
        }
            backdrop-filter: blur(10px);
            border-radius: 15px;
            padding: 2rem;
            border: 1px solid rgba(255, 255, 255, 0.1);
            box-shadow: 0 8px 32px rgba(0, 0, 0, 0.3);
            transition: all 0.3s ease;
        }
        
        .panel-title {
            font-size: 1.5rem;
            margin-bottom: 1rem;
            display: flex;
            align-items: center;
            gap: 0.5rem;
        }
        
        .model-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
            gap: 1rem;
            margin: 1rem 0;
        }
        
        .model-card {
            background: rgba(255, 255, 255, 0.05);
            backdrop-filter: blur(10px);
            border-radius: 10px;
            padding: 1.5rem;
            border: 1px solid rgba(255, 255, 255, 0.1);
            transition: all 0.3s ease;
            box-shadow: 0 8px 32px rgba(0, 0, 0, 0.3);
        }
        
        .model-card:hover {
            background: rgba(255, 255, 255, 0.1);
            transform: translateY(-5px);
            box-shadow: 0 20px 40px rgba(0, 0, 0, 0.3);
            border-color: rgba(102, 126, 234, 0.3);
        }
        
        .model-status {
            display: inline-block;
            padding: 0.25rem 0.75rem;
            border-radius: 15px;
            font-size: 0.8rem;
            margin-top: 0.5rem;
        }
        
        .status-active {
            background: #28a745;
            color: white;
        }
        
        .status-inactive {
            background: #dc3545;
            color: white;
        }
        
        .status-loading {
            background: #ffc107;
            color: black;
        }
        
        .chat-interface {
            background: rgba(255, 255, 255, 0.05);
            backdrop-filter: blur(10px);
            border-radius: 15px;
            padding: 2rem;
            margin: 2rem 0;
            border: 1px solid rgba(255, 255, 255, 0.1);
            box-shadow: 0 8px 32px rgba(0, 0, 0, 0.3);
        }
        
        .chat-messages {
            height: 400px;
            overflow-y: auto;
            background: rgba(0,0,0,0.3);
            border-radius: 10px;
            padding: 1rem;
            margin-bottom: 1rem;
        }
        
        .message {
            margin-bottom: 1rem;
            padding: 0.75rem;
            border-radius: 8px;
        }
        
        .message.user {
            background: rgba(255,255,255,0.1);
            margin-left: 2rem;
        }
        
        .message.ai {
            background: rgba(0,150,255,0.2);
            margin-right: 2rem;
        }
        
        .message.system {
            background: rgba(255,165,0,0.2);
            font-style: italic;
        }
        
        .chat-input {
            display: flex;
            gap: 1rem;
        }
        
        .chat-input input {
            flex: 1;
            padding: 1rem;
            border: 1px solid rgba(255,255,255,0.2);
            border-radius: 8px;
            background: rgba(255,255,255,0.05);
            backdrop-filter: blur(5px);
            color: white;
            font-size: 1rem;
        }
        
        .chat-input input::placeholder {
            color: rgba(255,255,255,0.6);
        }
        
        .btn {
            padding: 1rem 2rem;
            border: none;
            border-radius: 8px;
            cursor: pointer;
            font-size: 1rem;
            transition: all 0.3s ease;
        }
        
        .btn-primary {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            box-shadow: 0 4px 15px rgba(102, 126, 234, 0.3);
        }
        
        .btn-primary:hover {
            transform: translateY(-2px);
            box-shadow: 0 8px 25px rgba(102, 126, 234, 0.4);
        }
        
        .btn-secondary {
            background: rgba(255,255,255,0.05);
            backdrop-filter: blur(5px);
            color: white;
            border: 1px solid rgba(255,255,255,0.2);
        }
        
        .btn-secondary:hover {
            background: rgba(255,255,255,0.1);
            transform: translateY(-2px);
        }
        
        .provider-controls {
            display: flex;
            flex-wrap: wrap;
            gap: 1rem;
            margin: 1rem 0;
        }
        
        .provider-toggle {
            display: flex;
            align-items: center;
            gap: 0.5rem;
            padding: 0.5rem 1rem;
            background: rgba(255,255,255,0.1);
            border-radius: 20px;
            cursor: pointer;
            transition: all 0.3s ease;
        }
        
        .provider-toggle:hover {
            background: rgba(255,255,255,0.2);
        }
        
        .provider-toggle input {
            margin: 0;
        }
        
        .stats-row {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
            gap: 1rem;
            margin: 2rem 0;
        }
        
        .stat-card {
            background: rgba(255,255,255,0.1);
            border-radius: 10px;
            padding: 1.5rem;
            text-align: center;
        }
        
        .stat-number {
            font-size: 2rem;
            font-weight: bold;
            display: block;
            margin-bottom: 0.5rem;
            background: linear-gradient(45deg, #ffecd2, #fcb69f);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            background-clip: text;
        }
        
        .pulse {
            animation: pulse 2s infinite;
        }
        
        @keyframes pulse {
            0% { opacity: 1; }
            50% { opacity: 0.7; }
            100% { opacity: 1; }
        }
        
        .loading {
            display: none;
            text-align: center;
            margin: 1rem 0;
        }
        
        .spinner {
            display: inline-block;
            width: 20px;
            height: 20px;
            border: 3px solid rgba(255,255,255,0.3);
            border-radius: 50%;
            border-top-color: #fff;
            animation: spin 1s ease-in-out infinite;
        }
        
        @keyframes spin {
            to { transform: rotate(360deg); }
        }
        
        .collaboration-panel {
            background: rgba(255,255,255,0.05);
            border-radius: 15px;
            padding: 2rem;
            margin: 2rem 0;
        }
        
        .consensus-display {
            background: rgba(0,150,255,0.1);
            border-radius: 10px;
            padding: 1rem;
            margin: 1rem 0;
            border-left: 4px solid #0096ff;
        }
    </style>
</head>
<body>
    <div class="header">
        <h1>üß† AI Management Dashboard</h1>
        <p class="subtitle">Advanced Multi-AI Orchestration & Ollama Integration</p>
    </div>

    <div class="dashboard">
        <!-- AI Provider Status -->
        <div class="control-panel">
            <div class="panel-card">
                <div class="panel-title">
                    ü§ñ AI Providers
                </div>
                <div id="provider-status" class="model-grid">
                    <div class="loading">
                        <div class="spinner"></div>
                        Loading providers...
                    </div>
                </div>
                <div class="provider-controls" id="provider-controls">
                    <!-- Provider toggles will be populated here -->
                </div>
            </div>

            <div class="panel-card">
                <div class="panel-title">
                    üìä AI Statistics
                </div>
                <div class="stats-row">
                    <div class="stat-card">
                        <span class="stat-number pulse" id="active-models">0</span>
                        <div>Active Models</div>
                    </div>
                    <div class="stat-card">
                        <span class="stat-number pulse" id="requests-today">0</span>
                        <div>Requests Today</div>
                    </div>
                    <div class="stat-card">
                        <span class="stat-number pulse" id="accuracy-rate">0%</span>
                        <div>Accuracy Rate</div>
                    </div>
                </div>
            </div>
        </div>

        <!-- Ollama Models -->
        <div class="panel-card">
            <div class="panel-title">
                ü¶ô Ollama Models (mistral:latest, qwen2.5-coder:7b)
            </div>
            <div id="ollama-models" class="model-grid">
                <div class="loading">
                    <div class="spinner"></div>
                    Loading Ollama models...
                </div>
            </div>
            <button class="btn btn-secondary" onclick="refreshOllamaModels()">
                üîÑ Refresh Models
            </button>
        </div>

        <!-- AI Chat Interface -->
        <div class="chat-interface">
            <div class="panel-title">
                üí¨ Multi-AI Chat Interface
            </div>
            <div class="provider-controls">
                <label class="provider-toggle">
                    <input type="checkbox" id="provider-ollama" checked>
                    ü¶ô Ollama
                </label>
                <label class="provider-toggle">
                    <input type="checkbox" id="provider-openai">
                    ü§ñ OpenAI
                </label>
                <label class="provider-toggle">
                    <input type="checkbox" id="provider-anthropic">
                    üß† Anthropic
                </label>
                <label class="provider-toggle">
                    <input type="checkbox" id="provider-xai">
                    ‚ö° xAI/Grok
                </label>
            </div>
            <div class="chat-messages" id="chat-messages">
                <div class="message system">
                    ü§ñ Multi-AI Chat Interface Ready
                    <br>Select AI providers above and start chatting!
                </div>
            </div>
            <div class="chat-input">
                <input type="text" id="chat-input" placeholder="Ask multiple AI models about maintenance, predictions, or anything else...">
                <button class="btn btn-primary" onclick="sendMultiAIMessage()">
                    Send to All Selected AIs
                </button>
            </div>
        </div>

        <!-- AI Collaboration Panel -->
        <div class="collaboration-panel">
            <div class="panel-title">
                ü§ù AI Collaboration Features
            </div>
            <div class="control-panel">
                <div class="panel-card">
                    <h4>Predictive Maintenance</h4>
                    <p>Use multiple AI models to analyze equipment data and predict failures</p>
                    <button class="btn btn-primary" onclick="runPredictiveDemo()">
                        Run Demo Analysis
                    </button>
                </div>
                <div class="panel-card">
                    <h4>Consensus Building</h4>
                    <p>Get multiple AI perspectives and build consensus on important decisions</p>
                    <button class="btn btn-primary" onclick="runConsensusDemo()">
                        Demo Consensus
                    </button>
                </div>
                <div class="panel-card">
                    <h4>Code Generation</h4>
                    <p>Use qwen2.5-coder:7b and other models for CMMS code assistance</p>
                    <button class="btn btn-primary" onclick="runCodeDemo()">
                        Generate Code
                    </button>
                </div>
            </div>
            <div id="collaboration-results" class="consensus-display" style="display: none;">
                <!-- Collaboration results will appear here -->
            </div>
        </div>
    </div>

    <script>
        let selectedProviders = ['ollama'];
        
        // Initialize dashboard
        document.addEventListener('DOMContentLoaded', function() {
            loadProviderStatus();
            loadAIStats();
            loadOllamaModels();
            
            // Setup chat input
            document.getElementById('chat-input').addEventListener('keypress', function(e) {
                if (e.key === 'Enter') {
                    sendMultiAIMessage();
                }
            });
            
            // Setup provider toggles
            document.querySelectorAll('input[id^="provider-"]').forEach(checkbox => {
                checkbox.addEventListener('change', updateSelectedProviders);
            });
        });
        
        function updateSelectedProviders() {
            selectedProviders = [];
            document.querySelectorAll('input[id^="provider-"]:checked').forEach(checkbox => {
                const provider = checkbox.id.replace('provider-', '');
                selectedProviders.push(provider);
            });
        }
        
        async function loadProviderStatus() {
            try {
                const response = await fetch('/api/ai/providers');
                const data = await response.json();
                
                const container = document.getElementById('provider-status');
                container.innerHTML = '';
                
                Object.entries(data.providers).forEach(([provider, status]) => {
                    const card = document.createElement('div');
                    card.className = 'model-card';
                    
                    const statusClass = status.accessible ? 'status-active' : 'status-inactive';
                    const statusText = status.accessible ? 'ACTIVE' : 'INACTIVE';
                    
                    card.innerHTML = `
                        <h4>ü§ñ ${provider.toUpperCase()}</h4>
                        <p>Models: ${status.models.length}</p>
                        <div class="model-status ${statusClass}">${statusText}</div>
                        ${status.available_models ? `<small>Available: ${status.available_models.join(', ')}</small>` : ''}
                    `;
                    
                    container.appendChild(card);
                });
            } catch (error) {
                console.error('Failed to load provider status:', error);
            }
        }
        
        async function loadAIStats() {
            try {
                const response = await fetch('/api/ai/stats');
                const data = await response.json();
                
                document.getElementById('active-models').textContent = data.active_models || 0;
                document.getElementById('requests-today').textContent = data.predictions_today || 0;
                document.getElementById('accuracy-rate').textContent = (data.accuracy_rate || 0) + '%';
            } catch (error) {
                console.error('Failed to load AI stats:', error);
            }
        }
        
        async function loadOllamaModels() {
            try {
                const response = await fetch('/api/ai/ollama/models');
                const data = await response.json();
                
                const container = document.getElementById('ollama-models');
                container.innerHTML = '';
                
                if (data.available_models.length === 0) {
                    container.innerHTML = `
                        <div class="model-card">
                            <h4>‚ö†Ô∏è No Ollama Models</h4>
                            <p>Ollama service not available or no models installed</p>
                            <div class="model-status status-inactive">UNAVAILABLE</div>
                            <small>Install models: ollama pull mistral:latest</small>
                        </div>
                    `;
                } else {
                    data.available_models.forEach(model => {
                        const card = document.createElement('div');
                        card.className = 'model-card';
                        
                        const isRecommended = model.includes('mistral') || model.includes('qwen2.5-coder');
                        
                        card.innerHTML = `
                            <h4>ü¶ô ${model}</h4>
                            <p>${isRecommended ? '‚≠ê Recommended Model' : 'Available Model'}</p>
                            <div class="model-status status-active">READY</div>
                            <button class="btn btn-secondary" onclick="testOllamaModel('${model}')">
                                Test Model
                            </button>
                        `;
                        
                        container.appendChild(card);
                    });
                }
            } catch (error) {
                console.error('Failed to load Ollama models:', error);
                document.getElementById('ollama-models').innerHTML = `
                    <div class="model-card">
                        <h4>‚ùå Connection Error</h4>
                        <p>Could not connect to Ollama service</p>
                        <div class="model-status status-inactive">ERROR</div>
                    </div>
                `;
            }
        }
        
        async function sendMultiAIMessage() {
            const input = document.getElementById('chat-input');
            const message = input.value.trim();
            
            if (!message) return;
            
            // Add user message to chat
            addMessageToChat('user', message);
            input.value = '';
            
            if (selectedProviders.length === 0) {
                addMessageToChat('system', 'Please select at least one AI provider');
                return;
            }
            
            // Show loading
            addMessageToChat('system', 'Querying ' + selectedProviders.join(', ') + '...');
            
            try {
                const response = await fetch('/api/ai/multi-ai', {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json',
                    },
                    body: JSON.stringify({
                        prompt: message,
                        providers: selectedProviders,
                        parallel_execution: true,
                        consensus_required: selectedProviders.length > 1
                    })
                });
                
                const data = await response.json();
                
                // Display results from each provider
                Object.entries(data.results).forEach(([provider, result]) => {
                    const response_text = result.response || result.choices?.[0]?.message?.content || 'No response';
                    addMessageToChat('ai', `ü§ñ ${provider.toUpperCase()}: ${response_text}`);
                });
                
                // Display errors
                Object.entries(data.errors).forEach(([provider, error]) => {
                    addMessageToChat('system', `‚ùå ${provider.toUpperCase()} Error: ${error}`);
                });
                
                // Display consensus if available
                if (data.consensus) {
                    addMessageToChat('system', `ü§ù Consensus: ${data.consensus.summary}`);
                }
                
            } catch (error) {
                addMessageToChat('system', '‚ùå Error: ' + error.message);
            }
        }
        
        function addMessageToChat(type, content) {
            const chatMessages = document.getElementById('chat-messages');
            const messageDiv = document.createElement('div');
            messageDiv.className = `message ${type}`;
            messageDiv.innerHTML = content;
            chatMessages.appendChild(messageDiv);
            chatMessages.scrollTop = chatMessages.scrollHeight;
        }
        
        async function testOllamaModel(model) {
            try {
                addMessageToChat('system', `Testing ${model}...`);
                
                const response = await fetch('/api/ai/ollama/chat', {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json',
                    },
                    body: JSON.stringify({
                        model: model,
                        message: "Hello! Please respond with a brief introduction of your capabilities for CMMS maintenance analysis.",
                        temperature: 0.7
                    })
                });
                
                const data = await response.json();
                addMessageToChat('ai', `ü¶ô ${model}: ${data.response}`);
                
            } catch (error) {
                addMessageToChat('system', `‚ùå Test failed for ${model}: ${error.message}`);
            }
        }
        
        async function runPredictiveDemo() {
            document.getElementById('collaboration-results').style.display = 'block';
            document.getElementById('collaboration-results').innerHTML = '<div class="loading"><div class="spinner"></div> Running predictive maintenance analysis...</div>';
            
            try {
                const response = await fetch('/api/ai/collaboration/demo');
                const data = await response.json();
                
                document.getElementById('collaboration-results').innerHTML = `
                    <h4>üîÆ ${data.demo_scenario}</h4>
                    <p><strong>Available Providers:</strong> ${data.available_providers.join(', ')}</p>
                    <div class="stats-row">
                        <div class="stat-card">
                            <span class="stat-number">${Object.keys(data.collaboration_result.results).length}</span>
                            <div>AI Models Used</div>
                        </div>
                        <div class="stat-card">
                            <span class="stat-number">${Object.keys(data.collaboration_result.errors).length}</span>
                            <div>Errors</div>
                        </div>
                    </div>
                    <p><strong>Demo Insights:</strong></p>
                    <ul>
                        ${data.demo_insights.map(insight => `<li>${insight}</li>`).join('')}
                    </ul>
                `;
            } catch (error) {
                document.getElementById('collaboration-results').innerHTML = `‚ùå Demo failed: ${error.message}`;
            }
        }
        
        async function runConsensusDemo() {
            addMessageToChat('system', 'ü§ù Running consensus demo with multiple AI models...');
            
            const demoMessage = "What are the top 3 predictive maintenance priorities for industrial equipment?";
            
            const response = await fetch('/api/ai/multi-ai', {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json',
                },
                body: JSON.stringify({
                    prompt: demoMessage,
                    providers: selectedProviders.length > 0 ? selectedProviders : ['ollama'],
                    consensus_required: true,
                    parallel_execution: true
                })
            });
            
            const data = await response.json();
            
            Object.entries(data.results).forEach(([provider, result]) => {
                const response_text = result.response || result.choices?.[0]?.message?.content || 'No response';
                addMessageToChat('ai', `ü§ñ ${provider.toUpperCase()}: ${response_text}`);
            });
            
            if (data.consensus) {
                addMessageToChat('system', `ü§ù Consensus Result: ${data.consensus.summary}`);
            }
        }
        
        async function runCodeDemo() {
            addMessageToChat('system', 'üíª Generating CMMS code with qwen2.5-coder...');
            
            const codePrompt = "Generate a Python function for calculating equipment maintenance schedules based on usage hours and manufacturer recommendations";
            
            try {
                const response = await fetch('/api/ai/ollama/chat', {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json',
                    },
                    body: JSON.stringify({
                        model: 'qwen2.5-coder:7b',
                        message: codePrompt,
                        temperature: 0.3
                    })
                });
                
                const data = await response.json();
                addMessageToChat('ai', `üíª qwen2.5-coder: ${data.response}`);
                
            } catch (error) {
                // Fallback to any available model
                addMessageToChat('system', 'qwen2.5-coder not available, using alternative...');
                sendMultiAIMessage();
            }
        }
        
        function refreshOllamaModels() {
            loadOllamaModels();
        }
        
        // Auto-refresh stats every 30 seconds
        setInterval(loadAIStats, 30000);
    </script>
</body>
</html>