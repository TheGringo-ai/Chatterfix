version: '3.8'

# ChatterFix CMMS - Technician-First Maintenance Management
# Multi-Service Docker Compose for Local Development & Production

x-common-variables: &common-variables
  ENVIRONMENT: ${ENVIRONMENT:-production}
  USE_FIRESTORE: true
  LOG_LEVEL: ${LOG_LEVEL:-info}
  PYTHONPATH: /app

services:
  # Main ChatterFix CMMS Application
  core-web:
    build:
      context: .
      dockerfile: Dockerfile
      target: ${BUILD_TARGET:-production}
    image: gcr.io/fredfix/chatterfix-cmms:latest
    ports:
      - "${PORT:-8080}:8080"
    environment:
      <<: *common-variables
      PORT: 8080
      REDIS_URL: redis://redis:6379
      OCR_SERVICE_URL: http://ocr-service:8081
      AI_TEAM_SERVICE_URL: http://ai-team-service:8082
    env_file:
      - .env
    volumes:
      - ./secrets:/app/secrets:ro
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 45s
    restart: unless-stopped
    depends_on:
      redis:
        condition: service_healthy
      ocr-service:
        condition: service_healthy
      ai-team-service:
        condition: service_healthy
    networks:
      - chatterfix-network
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 2G
        reservations:
          cpus: '1.0'
          memory: 1G

  # OCR Service for Document Scanning (Tesseract, EasyOCR, QR codes)
  ocr-service:
    build:
      context: ./services/ocr-service
      dockerfile: Dockerfile
    image: gcr.io/fredfix/chatterfix-ocr:latest
    ports:
      - "8081:8081"
    environment:
      <<: *common-variables
      PORT: 8081
      SERVICE_NAME: ocr-service
    env_file:
      - .env
    volumes:
      - ocr_temp:/tmp/ocr
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8081/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    restart: unless-stopped
    networks:
      - chatterfix-network
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 2G
        reservations:
          cpus: '0.5'
          memory: 1G

  # AI Team Service for Multi-Model AI Collaboration (AutoGen)
  ai-team-service:
    build:
      context: ./ai-team-service
      dockerfile: Dockerfile
    image: gcr.io/fredfix/chatterfix-ai-team:latest
    ports:
      - "8082:8082"
    environment:
      <<: *common-variables
      PORT: 8082
      SERVICE_NAME: ai-team-service
      REDIS_URL: redis://redis:6379
    env_file:
      - .env
    volumes:
      - ./secrets:/app/secrets:ro
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8082/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    restart: unless-stopped
    depends_on:
      redis:
        condition: service_healthy
    networks:
      - chatterfix-network
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 4G
        reservations:
          cpus: '1.0'
          memory: 2G

  # Redis for session management and caching
  redis:
    image: redis:7-alpine
    command: redis-server --appendonly yes --maxmemory 256mb --maxmemory-policy allkeys-lru
    volumes:
      - redis_data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 15s
      timeout: 5s
      retries: 3
      start_period: 10s
    restart: unless-stopped
    networks:
      - chatterfix-network
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M

  # Nginx Reverse Proxy (for production)
  nginx:
    image: nginx:alpine
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf:ro
      - ./ssl:/etc/nginx/ssl:ro
    depends_on:
      - core-web
    restart: unless-stopped
    networks:
      - chatterfix-network
    profiles:
      - production

volumes:
  redis_data:
    driver: local
  ocr_temp:
    driver: local

networks:
  chatterfix-network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.0.0/24
